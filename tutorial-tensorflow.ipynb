{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.dpi\"] = 150\n",
    "rcParams[\"savefig.dpi\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import hemcee\n",
    "from hemcee.sampler import TFModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo is the same as the one in `tutorial.ipynb`, but using TensorFlow to define the model instead of computing the gradients by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log prob: -0.054823958751874714\n",
      "Initial gradient: [array([0.14671612, 0.04226426])]\n"
     ]
    }
   ],
   "source": [
    "# Generate a random covariance matrix\n",
    "np.random.seed(42)\n",
    "ndim = 2\n",
    "L = np.random.randn(ndim, ndim)\n",
    "L[np.diag_indices_from(L)] = np.exp(L[np.diag_indices_from(L)])\n",
    "L[np.triu_indices_from(L, 1)] = 0.0\n",
    "cov = np.dot(L, L.T)\n",
    "\n",
    "params = tf.Variable(np.random.multivariate_normal(np.zeros(ndim), cov), dtype=tf.float64)\n",
    "\n",
    "log_prob = -0.5 * tf.reduce_sum(params * tf.cholesky_solve(L, params[:, None])[:, 0])\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print(\"Initial log prob: {0}\".format(session.run(log_prob)))\n",
    "    print(\"Initial gradient: {0}\".format(\n",
    "        session.run(tf.gradients(log_prob, params))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to wrap the model, I would use this syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model value: -0.054823958751874714\n",
      "Model gradient: [0.14671612 0.04226426]\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "model = TFModel(log_prob, var_list=[params])\n",
    "model.setup()\n",
    "\n",
    "coords = model.current_vector()\n",
    "print(\"Model value: {0}\".format(model.value(coords)))\n",
    "print(\"Model gradient: {0}\".format(model.gradient(coords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value and gradients here should be the same as the ones that you got above.\n",
    "\n",
    "Then we set up the sampler using this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a dense metric that we will tune\n",
    "#metric = hemcee.metric.DenseMetric(np.eye(ndim))\n",
    "\n",
    "# We will also tune the step size\n",
    "step = hemcee.step_size.VariableStepSize()\n",
    "\n",
    "# Set up the sampler\n",
    "sampler = hemcee.NoUTurnSampler(model.value, model.gradient, step_size=step, metric=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Hamiltonian samplers require a tuning phase (often called \"warmup\" or \"burn in\").\n",
    "During this phase, the step size and metric are automatically tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initial warm up: step_size: 7.0e+00; mean(accept_stat): 0.503: 100%|██████████| 100/100 [00:01<00:00, 95.60it/s]\n",
      "warm up 1/8: step_size: 1.5e+00; mean(accept_stat): 0.503: 100%|██████████| 25/25 [00:00<00:00, 113.92it/s]\n",
      "warm up 2/8: step_size: 6.1e+00; mean(accept_stat): 0.498: 100%|██████████| 25/25 [00:00<00:00, 97.31it/s]\n",
      "warm up 3/8: step_size: 1.4e+00; mean(accept_stat): 0.508: 100%|██████████| 50/50 [00:00<00:00, 106.91it/s]\n",
      "warm up 4/8: step_size: 3.1e+00; mean(accept_stat): 0.500: 100%|██████████| 100/100 [00:00<00:00, 100.47it/s]\n",
      "warm up 5/8: step_size: 2.6e+00; mean(accept_stat): 0.503: 100%|██████████| 200/200 [00:01<00:00, 110.25it/s]\n",
      "warm up 6/8: step_size: 2.4e+00; mean(accept_stat): 0.502: 100%|██████████| 400/400 [00:03<00:00, 110.58it/s]\n",
      "warm up 7/8: step_size: 4.2e+00; mean(accept_stat): 0.501: 100%|██████████| 800/800 [00:05<00:00, 149.80it/s]\n",
      "warm up 8/8: step_size: 3.1e+00; mean(accept_stat): 0.501: 100%|██████████| 3200/3200 [00:17<00:00, 184.85it/s]\n",
      "final warm up: step_size: 3.3e+00; mean(accept_stat): 0.501: 100%|██████████| 100/100 [00:00<00:00, 182.33it/s]\n"
     ]
    }
   ],
   "source": [
    "coords = np.random.randn(ndim)\n",
    "results = sampler.run_warmup(coords, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After burning in, we can run the production MCMC chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step_size: 2.9e+00; mean(accept_stat): 0.601: 100%|██████████| 1000/1000 [00:19<00:00, 51.50it/s]\n"
     ]
    }
   ],
   "source": [
    "coords_chain, logprob_chain = sampler.run_mcmc(results[0], 1000, initial_log_prob=results[1], var_names=[None]*5, plot=True)\n",
    "#coords_chain, logprob_chain = sampler.run_mcmc(coords, 5000, initial_log_prob=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1d567f26a0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(np.exp(logprob_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#matplotlib.rcParams.update({'font.size': 7})\n",
    "figure = corner.corner(coords_chain, \n",
    "                       quantiles=[0.16, 0.5, 0.84],\n",
    "                       show_titles=True, title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = np.array([hemcee.autocorr.integrated_time(coords_chain[:, i])[0] for i in range(ndim)])\n",
    "print(\"Mean autocorrelation time: {0}\".format(np.mean(taus)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
